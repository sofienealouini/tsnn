{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tsnn.data_utils import *\n",
    "from tsnn.models import DeepRecurrent, LSTNet, DeepSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction task\n",
    "input_cols = []\n",
    "target_cols = [\"client_0\", \"client_6\", \"client_11\", \"client_36\", \"client_315\"]\n",
    "pred_delay = 24\n",
    "\n",
    "# Hyperparameters\n",
    "scaling_method = \"maxabs\"\n",
    "timesteps = 168\n",
    "batch_size = 64\n",
    "sampling_step = 1\n",
    "\n",
    "# Simple cross-validation\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv('electricity.txt', header=None)\n",
    "raw_data.columns = [\"client_\" + str(i) for i in range(len(raw_data.columns))] \n",
    "nb_features = max(len(input_cols), len(raw_data.columns))\n",
    "\n",
    "# Converting column names to their indices (necessary for LSTNet only)\n",
    "target_cols_indices = colnames_to_colindices(interest_cols=target_cols, original_df=raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data generators\n",
    "generators_dict, stats_df = prepare_data_generators(raw_data=raw_data, \n",
    "                                                    input_cols=input_cols, \n",
    "                                                    target_cols=target_cols,     # We use the column NAMES here\n",
    "                                                    scaling_method=\"maxabs\", \n",
    "                                                    samples_length=timesteps, \n",
    "                                                    pred_delay=pred_delay,\n",
    "                                                    sampling_step=sampling_step, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    train_ratio=train_ratio, \n",
    "                                                    val_ratio=val_ratio)\n",
    "\n",
    "train_gen, train_gen_steps = generators_dict[\"train\"]\n",
    "val_gen, val_gen_steps = generators_dict[\"val\"]\n",
    "test_gen, test_gen_steps = generators_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "lstnet = LSTNet(input_shape=(timesteps, nb_features), \n",
    "                interest_vars=target_cols_indices,     # We use the column INDICES here ## A CORRIGER (partial inputs)\n",
    "                cnn_filters=100, \n",
    "                cnn_kernel_height=6, \n",
    "                cnn_activation='relu', \n",
    "                cnn_use_bias=True,\n",
    "                gru_units=100, \n",
    "                gru_activation='relu', \n",
    "                gru_use_bias=True,\n",
    "                gru_skip_units=5, \n",
    "                gru_skip_step=24, \n",
    "                gru_skip_activation='relu', \n",
    "                gru_skip_use_bias=True,\n",
    "                ar_window=24, \n",
    "                ar_use_bias=True, \n",
    "                dropout=0.2)\n",
    "lstnet.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 156s - loss: 0.1232 - val_loss: 0.1081\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 154s - loss: 0.1034 - val_loss: 0.0965\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 154s - loss: 0.0916 - val_loss: 0.0883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x104b1ee48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "lstnet.fit_generator(generator=train_gen, \n",
    "                     steps_per_epoch=train_gen_steps, \n",
    "                     validation_data=val_gen, \n",
    "                     validation_steps=val_gen_steps,\n",
    "                     epochs=3, \n",
    "                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5222, 5)\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "pred_test_gen = yield_inputs_only(test_gen)\n",
    "lstnet_preds = lstnet.predict_generator(generator=pred_test_gen, steps=test_gen_steps)\n",
    "print(lstnet_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DeepRecurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "deeprec = DeepRecurrent(input_shape=(timesteps,nb_features),\n",
    "                        rec_layers_dims=[64,32], \n",
    "                        rec_layer_type=\"lstm\", \n",
    "                        rec_use_bias=True, \n",
    "                        rec_activation='tanh',\n",
    "                        output_dim=5, \n",
    "                        dense_use_bias=True, \n",
    "                        dropout=0.2, \n",
    "                        attention_dim=\"timesteps\")\n",
    "deeprec.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 225s - loss: 0.1666 - val_loss: 0.1635\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 228s - loss: 0.1519 - val_loss: 0.1467\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 228s - loss: 0.1511 - val_loss: 0.1462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10dbfac18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "deeprec.fit_generator(generator=train_gen, \n",
    "                      steps_per_epoch=train_gen_steps, \n",
    "                      validation_data=val_gen, \n",
    "                      validation_steps=val_gen_steps,\n",
    "                      epochs=3, \n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5222, 5)\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "pred_test_gen = yield_inputs_only(test_gen)\n",
    "deeprec_preds = deeprec.predict_generator(generator=pred_test_gen, steps=test_gen_steps)\n",
    "print(deeprec_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DeepSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data generators for DeepSense\n",
    "deepsense_timesteps = 1000\n",
    "ds_generators_dict, ds_stats_df = prepare_data_generators(raw_data=raw_data, \n",
    "                                                    input_cols=input_cols, \n",
    "                                                    target_cols=target_cols,     # We use the column NAMES here\n",
    "                                                    scaling_method=\"maxabs\", \n",
    "                                                    samples_length=deepsense_timesteps, \n",
    "                                                    pred_delay=pred_delay,\n",
    "                                                    sampling_step=sampling_step, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    train_ratio=train_ratio, \n",
    "                                                    val_ratio=val_ratio)\n",
    "\n",
    "ds_train_gen, ds_train_gen_steps = ds_generators_dict[\"train\"]\n",
    "ds_val_gen, ds_val_gen_steps = ds_generators_dict[\"val\"]\n",
    "ds_test_gen, ds_test_gen_steps = ds_generators_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "deepsense = DeepSense(sensor_dims_list=[321],\n",
    "                      sequence_length=deepsense_timesteps,\n",
    "                      time_window_tau=8,\n",
    "                      freq_domain=False,\n",
    "                      cnn_filters=64,\n",
    "                      cnn1_kernel_height=2,\n",
    "                      cnn2_kernel_size=3,\n",
    "                      cnn3_kernel_size=2,\n",
    "                      cnn4_kernel_height=2,\n",
    "                      cnn5_kernel_size=3,\n",
    "                      cnn6_kernel_size=2,\n",
    "                      cnn_activation='relu',\n",
    "                      cnn_use_bias=True,\n",
    "                      gru_units=32,\n",
    "                      gru_use_bias=True,\n",
    "                      gru_activation='relu',\n",
    "                      dropout=0.1,\n",
    "                      output_dim=5)\n",
    "deepsense.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "deepsense.fit_generator(generator=ds_train_gen, \n",
    "                      steps_per_epoch=ds_train_gen_steps, \n",
    "                      validation_data=ds_val_gen, \n",
    "                      validation_steps=ds_val_gen_steps,\n",
    "                      epochs=3, \n",
    "                      shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}