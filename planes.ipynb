{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tsnn.data_utils import *\n",
    "from tsnn.models import DeepRecurrent, LSTNet, DeepSense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "path = \"/Users/sofiene/Desktop/states_2017-08-07-00.csv\"\n",
    "\n",
    "# Prediction task\n",
    "input_cols = [\"time\", \"lat\", \"lon\", \"velocity\", \"heading\"]\n",
    "input_cols_with_planes = [\"time\", \"icao24\", \"lat\", \"lon\", \"velocity\", \"heading\"]\n",
    "target_cols = [\"lat\", \"lon\"]\n",
    "target_cols_with_planes = [\"icao24\", \"lat\", \"lon\"]\n",
    "pred_delay = 1\n",
    "\n",
    "# Hyperparameters\n",
    "scaling_method = \"maxabs\"\n",
    "timesteps = 30\n",
    "batch_size = 64\n",
    "sampling_step = 1\n",
    "\n",
    "# Simple cross-validation\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function\n",
    "\n",
    "def my_generator(inputs_with_planes, targets_with_planes, limits=None, samples_length=168, sampling_step=1, batch_size=24):\n",
    "\n",
    "    if limits is None:\n",
    "        limits = (0, len(targets_with_planes))\n",
    "\n",
    "    inp_row = limits[0]\n",
    "    tar_row = limits[0]\n",
    "    inp_batch = []\n",
    "    tar_batch = []\n",
    "\n",
    "    while inp_row < limits[1]:\n",
    "        inp = inputs_with_planes.iloc[inp_row:inp_row + samples_length]\n",
    "        tar = targets_with_planes.iloc[tar_row]\n",
    "        if (len(inp[\"icao24\"].unique()) == 1) & (inp[\"icao24\"].iloc[-1] == tar.iloc[0]):\n",
    "            inp = inp.drop('icao24', axis=1).values\n",
    "            tar = tar.drop('icao24').values\n",
    "            inp_batch.append(inp)\n",
    "            tar_batch.append(tar)\n",
    "\n",
    "        if len(inp_batch) == batch_size or (inp_row + sampling_step) >= limits[1]:\n",
    "            yield np.array(inp_batch), np.array(tar_batch)\n",
    "            inp_batch = []\n",
    "            tar_batch = []\n",
    "        inp_row += sampling_step\n",
    "        tar_row += sampling_step\n",
    "\n",
    "        if inp_row >= limits[1]:\n",
    "            inp_row = limits[0]\n",
    "            tar_row = limits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and sort data\n",
    "raw_data = pd.read_csv(path)\n",
    "raw_data_all_planes = raw_data[input_cols_with_planes].sort_values([\"icao24\", \"time\"])\n",
    "raw_data_all_planes.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Handle NaNs\n",
    "clean_data = raw_data_all_planes.ffill().bfill()\n",
    "\n",
    "# Scale\n",
    "scaled, stats_df = scaling(clean_data[input_cols], \"maxabs\")\n",
    "scaled_with_planes = pd.concat([scaled[[\"time\"]], \n",
    "                                clean_data[[\"icao24\"]], \n",
    "                                scaled[[\"lat\", \"lon\", \"velocity\", \"heading\"]]], axis=1)\n",
    "\n",
    "# Inputs / Targets\n",
    "inputs, targets = inputs_targets_split(scaled_with_planes, \n",
    "                                       input_cols_with_planes, \n",
    "                                       target_cols_with_planes, \n",
    "                                       timesteps, \n",
    "                                       pred_delay)\n",
    "\n",
    "# Train / Val / Test split\n",
    "train_idx, val_idx, test_idx = train_val_split(targets, train_ratio, val_ratio)\n",
    "\n",
    "# Prepare generators\n",
    "train_gen = my_generator(inputs, targets, train_idx, timesteps, sampling_step, batch_size)\n",
    "train_gen_steps = compute_generator_steps(train_idx, sampling_step, batch_size)\n",
    "\n",
    "val_gen = my_generator(inputs, targets, val_idx, timesteps, sampling_step, batch_size)\n",
    "val_gen_steps = compute_generator_steps(val_idx, sampling_step, batch_size)\n",
    "\n",
    "test_gen = my_generator(inputs, targets, test_idx, timesteps, sampling_step, batch_size)\n",
    "test_gen_steps = compute_generator_steps(test_idx, sampling_step, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols_indices = [1, 2] # indices in the scaled df (without icao24)\n",
    "\n",
    "# Create model\n",
    "lstnet = LSTNet(input_shape=(timesteps, len(input_cols)), \n",
    "                interest_vars=target_cols_indices,\n",
    "                cnn_filters=100, \n",
    "                cnn_kernel_height=6, \n",
    "                cnn_activation='relu', \n",
    "                cnn_use_bias=True,\n",
    "                gru_units=100, \n",
    "                gru_activation='relu', \n",
    "                gru_use_bias=True,\n",
    "                gru_skip_units=5, \n",
    "                gru_skip_step=6, \n",
    "                gru_skip_activation='relu', \n",
    "                gru_skip_use_bias=True,\n",
    "                ar_window=6, \n",
    "                ar_use_bias=True, \n",
    "                dropout=0.2)\n",
    "lstnet.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a44c8b4e924a07b866dfbd30a4742c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0561b2e8517547daaf8dd5427b00412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=15278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Train the model\n",
    "lstnet.fit_generator(generator=train_gen, \n",
    "                     steps_per_epoch=train_gen_steps, \n",
    "                     validation_data=val_gen, \n",
    "                     validation_steps=val_gen_steps,\n",
    "                     epochs=1, \n",
    "                     shuffle=False,\n",
    "                     verbose=0,\n",
    "                     callbacks=[TQDMNotebookCallback(leave_inner=True, leave_outer=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
